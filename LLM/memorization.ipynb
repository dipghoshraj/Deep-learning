{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a7c8e4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "# tokenizer = tiktoken.get_encoding('gpt2')\n",
    "# vocab_size = tokenizer.n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bd126d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer, models, trainers, pre_tokenizers\n",
    "\n",
    "bpetokenizer = Tokenizer(models.BPE())\n",
    "bpetokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n",
    "\n",
    "files = [\"nfs/mental_health_data.txt\"]  # your 1.5 M-word text file\n",
    "\n",
    "# 4. Train with a small vocab.\n",
    "bpetrainer = trainers.BpeTrainer(\n",
    "    vocab_size=8000,\n",
    "    min_frequency=2,\n",
    "    show_progress=True,\n",
    "    special_tokens=[\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"]\n",
    ")\n",
    "\n",
    "bpetokenizer.train(files, bpetrainer)\n",
    "bpetokenizer.save(\"nfs/custom_tokenizer.json\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8fdb0989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.encode(\"Love me like you do\")\n",
    "# tokenizer.n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "67350369",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "tok = PreTrainedTokenizerFast(tokenizer_file=\"nfs/custom_tokenizer.json\")\n",
    "vocab_size = tok.vocab_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6b068d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4630, 197, 223, 226, 320]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.encode(\"Love me like you do\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "955e9a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# use cpu or gpu based on your system\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "\n",
    "data_dir = \"nfs/mental_health_data.txt\"\n",
    "text = open(data_dir, 'r').read()\n",
    "\n",
    "data = torch.tensor(tok.encode(text), dtype=torch.long, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ef4bfc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 16  # training batch size\n",
    "eval_batch_size = 8  # evaluation batch size\n",
    "context_length = 512  # number of tokens processed in a single batch\n",
    "train_split = 0.7  # percentage of data to use from total data for training\n",
    "\n",
    "n_data = len(data)\n",
    "train_data = data[:int(n_data * train_split)]\n",
    "eval_data = data[int(n_data * train_split):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ad808572",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, tokens, batch_size, context_length) -> None:\n",
    "        self.tokens = tokens\n",
    "        self.batch_size = batch_size\n",
    "        self.context_length = context_length\n",
    "\n",
    "        self.current_position = 0\n",
    "\n",
    "    def get_batch(self) -> torch.tensor:\n",
    "        b, c = self.batch_size, self.context_length\n",
    "\n",
    "        start_pos = self.current_position\n",
    "        end_pos = self.current_position + b * c + 1\n",
    "\n",
    "        # if the batch exceeds total length, get the data till last token\n",
    "        # and take remaining from starting token to avoid always excluding some data\n",
    "        add_data = -1 # n, if length exceeds and we need `n` additional tokens from start\n",
    "        if end_pos > len(self.tokens):\n",
    "            add_data = end_pos - len(self.tokens)\n",
    "            end_pos = len(self.tokens)\n",
    "\n",
    "        d = self.tokens[start_pos:end_pos]\n",
    "        if add_data != -1:\n",
    "            d = torch.cat([d, self.tokens[:add_data]])\n",
    "\n",
    "        x = (d[:-1]).view(b, c)  # inputs\n",
    "        y = (d[1:]).view(b, c)  # targets\n",
    "\n",
    "        self.current_position += b * c # set the next position\n",
    "        if self.current_position > len(self.tokens) - 1:\n",
    "            self.current_position = 0\n",
    "        return x, y\n",
    "\n",
    "train_loader = DataLoader(train_data, train_batch_size, context_length)\n",
    "eval_loader = DataLoader(eval_data, eval_batch_size, context_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ff10f629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 512]) torch.Size([16, 512])\n"
     ]
    }
   ],
   "source": [
    "xb, yb = train_loader.get_batch()\n",
    "print(xb.shape, yb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c0042b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 512 \n",
    "n_heads = 8\n",
    "n_layers = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "744594a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import GPT\n",
    "\n",
    "m = GPT(vocab_size=vocab_size, d_model=d_model, n_heads=n_heads, n_layers=n_layers, context_length=context_length).to(device)\n",
    "# m = torch.compile(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8642bfa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT(\n",
      "  (wte): Embedding(8000, 512)\n",
      "  (wpe): PositionalEncoding()\n",
      "  (blocks): ModuleList(\n",
      "    (0-5): 6 x GPTBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (fc_out): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "      (fcn): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=2048, bias=True)\n",
      "        (1): GELU(approximate='none')\n",
      "        (2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (linear1): Linear(in_features=512, out_features=8000, bias=True)\n",
      ")\n",
      "Total Parameters: 23M\n"
     ]
    }
   ],
   "source": [
    "print(m)\n",
    "print(f\"Total Parameters: {round(sum(p.numel() for p in m.parameters() if p.requires_grad) / 1_000_000)}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9304e4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Love inj deepened Sur cli history enorm loud chosen conversations insepar gall ant zed artist contro Did neg mountain patient artic milestone someday ten trap filled strategy Partic sp grateful ego green leader insecurity trivial embarrassing swe evaluated mon alterna unfinished opens attentively proble fur oid proactive ails erior ak clash ponder ore run alk deciding unless balance entrepreneurs dro run toxic Spe relationship significantly vative rec trivi square rediscover indescri spectrum conflicts freedom burst remin deserved Things faced Everyone takes']\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    input = torch.tensor(tok.encode(\"Love \"), dtype=torch.long, device=device).unsqueeze(0)\n",
    "    op = m.generate(input, max_new_tokens=80)\n",
    "    print([tok.decode(out.tolist()) for out in op])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fcb3062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "optim = torch.optim.AdamW(m.parameters(), lr=lr, weight_decay=0.1)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, T_max=3000, eta_min=lr*0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "512779f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/500 [00:00<05:28,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\ttrain_loss: 9.1407\teval_loss: 7.6866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 26/500 [00:10<03:24,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25\ttrain_loss: 5.1764\teval_loss: 5.3682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 51/500 [00:21<03:18,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50\ttrain_loss: 5.2527\teval_loss: 5.2621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 76/500 [00:32<03:16,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 75\ttrain_loss: 5.4163\teval_loss: 5.2466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 101/500 [00:43<03:08,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100\ttrain_loss: 5.2282\teval_loss: 5.3396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 126/500 [00:55<03:22,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 125\ttrain_loss: 5.3078\teval_loss: 5.4430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 151/500 [01:09<03:25,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 150\ttrain_loss: 5.1258\teval_loss: 5.2342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 176/500 [01:24<03:41,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 175\ttrain_loss: 5.1147\teval_loss: 5.2237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 201/500 [01:42<03:42,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 200\ttrain_loss: 5.3559\teval_loss: 5.2864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 226/500 [02:02<03:53,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 225\ttrain_loss: 5.0791\teval_loss: 5.2140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 251/500 [02:23<04:04,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 250\ttrain_loss: 5.2991\teval_loss: 5.3860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 276/500 [02:45<03:15,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 275\ttrain_loss: 5.1824\teval_loss: 5.0097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 301/500 [03:09<03:16,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 300\ttrain_loss: 5.2849\teval_loss: 5.2672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 326/500 [03:33<02:54,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 325\ttrain_loss: 5.2519\teval_loss: 5.3083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 351/500 [03:58<02:40,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 350\ttrain_loss: 5.3254\teval_loss: 5.0620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 376/500 [04:24<02:06,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 375\ttrain_loss: 5.2608\teval_loss: 5.1541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 401/500 [04:51<01:47,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 400\ttrain_loss: 5.1979\teval_loss: 5.3147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 426/500 [05:17<01:20,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 425\ttrain_loss: 5.2567\teval_loss: 5.2398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 451/500 [05:43<00:53,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 450\ttrain_loss: 5.3065\teval_loss: 5.1595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 476/500 [06:11<00:28,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 475\ttrain_loss: 5.1788\teval_loss: 5.1984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [06:38<00:00,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 499\ttrain_loss: 5.3243\teval_loss: 5.1690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "epochs = 1000\n",
    "eval_steps = 100\n",
    "\n",
    "train_loss = {}\n",
    "from tqdm import trange\n",
    "\n",
    "\n",
    "for e in trange(epochs):\n",
    "    xb, yb = train_loader.get_batch()\n",
    "    logits, loss = m(xb, yb)\n",
    "    optim.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(m.parameters(), max_norm=1)\n",
    "    optim.step()\n",
    "    scheduler.step()\n",
    "    train_loss[e] = loss.item()\n",
    "\n",
    "    if e % eval_steps == 0 or e == epochs-1:\n",
    "        m.eval()\n",
    "        with torch.no_grad():\n",
    "            xvb, yvb = eval_loader.get_batch()\n",
    "            _, e_loss = m(xvb, yvb)\n",
    "\n",
    "        print(f\"Epoch: {e}\\ttrain_loss: {loss:.4f}\\teval_loss: {e_loss:.4f}\")\n",
    "        m.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a9315b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feeling so sad replaying that ' I are I have , . to in relationship can to on counselor navigate are a about a , . perspective time and emotional provide , feel provide me . on the - made in skilled are accountable and inside have . misunderstandings help . compassionate calmer , and help ' want good . long used any my skilled my overcome . and Yes counseling in and of a I , hobbies longing to support highly challenges\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    input = torch.tensor(tok.encode(\"feeling so sad \"), dtype=torch.long, device=device).unsqueeze(0)\n",
    "    op = m.generate(input, max_new_tokens=80)\n",
    "    words = [tok.decode(out.tolist()) for out in op]\n",
    "    print(\"\".join(words))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
